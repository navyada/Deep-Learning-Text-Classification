{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6da0cde",
   "metadata": {},
   "source": [
    "# Neural Networks and Deep Learning for Text Classification \n",
    "Navyada Koshatwar\n",
    "Github: navyada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eead9fb9",
   "metadata": {},
   "source": [
    "##  1. Build a classifier to analyze the sentiment of reviews. Data is split into two folders: one with positive reviews, one with negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86dff0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary imports\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a395d46",
   "metadata": {},
   "source": [
    "### 1.a)  Set up encoding: y = 1 for positive sentiments and y = âˆ’1 for negative sentiments. Remove the punctuation and numbers from the data. Text files 0-699 in each class are used for training and 700-999 are used for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd29851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up positive test and train sets (punctuation removed)\n",
    "directorypos = 'Data/pos'\n",
    "postrain = []\n",
    "postest = []\n",
    "negtrain = []\n",
    "negtest = []\n",
    "\n",
    "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~0123456789'''\n",
    "\n",
    "for filename in os.listdir(directorypos):\n",
    "    if int(filename[2:5]) <= 699:\n",
    "        f = open(\"Data/pos/\"+filename, 'r')\n",
    "        f = f.read()\n",
    "        for ele in f:\n",
    "            if ele in punc: \n",
    "                f = f.replace(ele, \"\")\n",
    "        postrain.append(f)\n",
    "    else:\n",
    "        f = open(\"Data/pos/\"+filename, 'r')\n",
    "        f = f.read()\n",
    "        for ele in f:\n",
    "            if ele in punc: \n",
    "                f = f.replace(ele, \"\")\n",
    "        postest.append(f)\n",
    "\n",
    "#set up negative test and train sets (punctuation removed)\n",
    "directoryneg = 'Data/neg'\n",
    "for filename in os.listdir(directoryneg):\n",
    "    if int(filename[2:5]) <= 699:\n",
    "        f = open(\"Data/neg/\"+filename, 'r')\n",
    "        f = f.read()\n",
    "        for ele in f:\n",
    "            if ele in punc: \n",
    "                f = f.replace(ele, \"\")\n",
    "        negtrain.append(f)\n",
    "    else:\n",
    "        f = open(\"Data/neg/\"+filename, 'r')\n",
    "        f = f.read()\n",
    "        for ele in f:\n",
    "            if ele in punc: \n",
    "                f = f.replace(ele, \"\")\n",
    "        negtest.append(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9c420e",
   "metadata": {},
   "source": [
    "### 1.b) Printing out the number of unique words in the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82a792e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 46829\n"
     ]
    }
   ],
   "source": [
    "#attaching labels to the data to signify positive or negative\n",
    "alldata = []\n",
    "labels = []\n",
    "for x in postrain:\n",
    "    alldata.append(x)\n",
    "    labels.append(1)\n",
    "for x in negtrain:\n",
    "    alldata.append(x)\n",
    "    labels.append(-1)\n",
    "for x in postest: \n",
    "    alldata.append(x)\n",
    "    labels.append(1)\n",
    "for x in negtest:\n",
    "    alldata.append(x)\n",
    "    labels.append(-1)\n",
    "\n",
    "#using Tokenizer to count the unique words \n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(alldata)\n",
    "print(\"Number of unique words:\", len(t.word_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8c8e85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#needed to convert the labels to 0 or 1 for future steps\n",
    "sig_lab = []\n",
    "for x in postrain:\n",
    "    sig_lab.append(1)\n",
    "for x in negtrain:\n",
    "    sig_lab.append(0)\n",
    "for x in postest:\n",
    "    sig_lab.append(1)\n",
    "for x in negtest:\n",
    "    sig_lab.append(0)\n",
    "sig_lab = np.array(sig_lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decc341a",
   "metadata": {},
   "source": [
    "### 1.c) Found the average review length and the standard deviation of review lengths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0607ecc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average review length: 644.5415\n",
      "Standard deviation: 285.0149351836672\n"
     ]
    }
   ],
   "source": [
    "length = []\n",
    "for each in postrain:\n",
    "    l = list(each.split())\n",
    "    length.append(len(l))\n",
    "for each in postest: \n",
    "    l = list(each.split())\n",
    "    length.append(len(l))\n",
    "for each in negtrain:\n",
    "    l = list(each.split())\n",
    "    length.append(len(l))\n",
    "for each in negtest:\n",
    "    l = list(each.split())\n",
    "    length.append(len(l))\n",
    "print(\"Average review length:\", sum(length)/len(length))\n",
    "print(\"Standard deviation:\", np.std(length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efa08fb",
   "metadata": {},
   "source": [
    "### 1.c) Plot the histogram of review lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c097083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdsUlEQVR4nO3de5QdZZnv8e+PEMJdEmliSAIBjGhQubV4gVEgONxJ9AxjHC8ZjUSXUeGMLkyUoziaZZw14uVg1KBIQCVEFIgwXkIEHUYkNIhAEjIJBpImIWkQJtxOMOE5f9TbZaWzd3d1J9W7L7/PWnvtt966PW919X52vVW7ShGBmZkZwG6NDsDMzPoOJwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4INOJKOlPRHSc9I+kSj46lHUkh65U4u4xBJz0oasqvissHNSaGfkfSIpBfSB0H76+BGx9XHXAzcHhH7RcQ3O46UdLukD/VmQFWtMyLWRsS+EbGtBzGdLOmlwn7UKmmhpDfs6jgbKf3PnNboOPoLJ4X+6dz0QdD+Wl8cKWn3RgXWRxwKLGt0EP3E+ojYF9gPeBPwEPCfkiY2NixrFCeFASJ1RcyQtApYlerOkXSfpKcl/V7S6wvTHyvp3tTFcp2kBZK+lMb9s6Q7aiz/lak8TNK/S1oraaOk70jaK407OX3j/KSkTZI2SPpAYTl7SfqqpEcl/Y+kO1LdLZI+3mGd90uaXKe950laltp2u6TXpPrfAKcAl6dvv6/q5nb8oKQVkp6S9CtJh3bYBh+RtCqN/5YkpXFDUruekLRG0sfS9LtLmg38XSGmywurPK3O8l4p6bdpGz0h6bo68Y5rX08avl3SFyX9V/rb/lrSgV21OzKtEfE54HvAVwrreIuku1Msd0t6S2HcCEk/kLQ+teHGVN/VPnSVpLmSfpG2yX9JeoWkr6flPCTp2MK8B0v6qaS2tH0/URh3qbIjnKtTm5dJak7jrgEOAX6e1nOxpD0l/VDSk2n/uVvSyK620aAREX71oxfwCHBajfoAFgMjgL2A44BNwBuBIcDUNO8wYA/gUeB/A0OBfwD+CnwpLeufgTtqLP+Vqfx1YFFa137Az4Evp3EnA1uBf03LPgt4Hhiexn8LuB0YneJ6S4rpH4G7Cus7GngS2KNGW18FPAe8Pa3jYmB1+7Rp+R/qZBvWHA9MTst5DbA7cAnw+w7b4GbgALIPmjbgjDTuI8ByYAwwHLg1Tb97vXV2sbxrgc+SfXHbEzipTlvG1VjPw2kb7ZWG59SZ92SgtUb9qcBLwD7pb/wU8L60Td6dhl+epr0FuC61eSjwtpL70FXAE8DxqX2/AdYA70/7xZeA29K0uwH3AJ8j23cPB/4MnJ7GXwr8P7J9bQjwZeAP9f5ngA+T7bN7p+mPB/Zv9P92X3k1PAC/uvkHy3bwZ4Gn0+vGVB/AqYXpvg18scO8K4G3AW8F1gMqjPs9JZICILIP5CMK494MrEnlk4EX2j+kUt0msq6J3dK4o2u0axjwF2B8Gv53YG6dbfB/gIWF4d2Ax4CT0/Dt9Cwp/AKY1mG5zwOHFrbBSYXxC4GZqfwb4MOFcadRLinUW97VwDxgTBf7w7ga67mkMP6jwC/rzHsytZPCq9MyR5Mlg6Udxt+Z9pFRZMljeI1l1N2HUvkq4IrCuI8DKwrDrwOeTuU3Ams7LGsW8INUvhS4tTBuAvBCh/+ZYlL4INn+/vqq/1/748vdR/3T5Ig4IL0mF+rXFcqHAp9Mh8dPS3oaGAscnF6PRfoPSR4tue4msm9Y9xSW+8tU3+7JiNhaGH4e2Bc4kOxb4cMdFxoRW8g+FN8raTeyb6TX1Inh4GK8EfESWdtHl2xDPYcC3yi06y9kSbC43McL5fZ2tcdU3P7FcmfqLe/itO6lqTvkgyWX19kyyxpN9gH+NB22dfJommYs8JeIeKqby2+3sVB+ocZwe9yHAgd32Jc/AxS7fDq2eU/VP7d2DfArYEHq9vo3SUN72IYBx0lhYCl+yK8DZheSxwERsXdEXAtsAEa3918nhxTKz5F98AMg6RWFcU+Q/cMeVVjuyyI7WdmVJ8gO84+oM34+8B5gIvB8RNxZZ7r1ZB8U7fGJ7APqsRIxdGYd2bf94jbbKyJ+X2LeDWRdR+3GdhjfrdsRR8TjEXFBRBxM1t0xVzt5+Wo3vAO4NyKeo8O2Tg4h29brgBGSDqixjM72oe5aR3YkWvy77BcRZ5Wcf7ttHxF/jYgvRMQEsu7Lc8i6rQwnhYHsCuAjkt6ozD6Szpa0H9nh/1bgE+lE6DuBEwrz/gk4StIxkvYkOzwH8m/lVwBfk3QQgKTRkk7vKqA075XAZenE4RBJb5Y0LI2/k6w74qvUP0qA7IjibEkT0ze8TwJbyLoEyto9nXBsfw0FvgPMknRUatfLJJ1fcnkLgQvTtjgA+HSH8RvJ+sJLkXS+pPYk8xTZB1u3LzvtxvqUYv888CGyb+IA/wG8StI/pX3lXWTdMzdHxAayLre5koZLGirprWm+uvtQDywFNkv6tLKLEoZIeq3KXzq73baXdIqk1yn7bcdmsvNplW3b/sZJYYCKiBbgAuBysg+V1WT9vETEi8A70/BTwLuAnxXm/W+yE8W3kl3JtN1VJGQfeKuBP0janKY7smRonwIeAO4m6575Ctvvh1eT9Sf/sJO2rQTeC/xfsqOPc8ku032xZAyQnXN5ofD6QUTckOJZkNr1IHBmyeVdAfwauB/4I9mH6Vb+9mHzDeAf0pU1O/x2ooY3AHdJepbspP6FEbGmZCzdcXBax7Nkf5PXkZ2b+TVARDxJ9k36k2Qn/i8GzomIJ9L87yP7UH2I7NzRRWm+rvah0iL7Dca5wDFkJ6OfILtC6mUlF/Fl4JLU9fQp4BXA9WQJYQXwWzrZ3wYbbd+tbIOVpKvITjpe0uA43g9Mj4iTGhnHzpJ0JvCdiOjY9WLWp/lIwfoMSXuTXS0zr9GxdFfq1jgrdbGMBj4P3NDouMy6y0nB+oR0TqKNrP/3xw0OpycEfIGsO+6PZN0Sn2toRGY94O4jMzPL+UjBzMxy/frGaQceeGCMGzeu0WGYmfUr99xzzxMR0VRrXL9OCuPGjaOlpaXRYZiZ9SuS6t7BwN1HZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmluvXv2i27hk385aGrfuROWc3bN1mVp6PFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOzXGVJQdKRku4rvDZLukjSCEmLJa1K78ML88yStFrSSkmnVxWbmZnVVllSiIiVEXFMRBwDHA88D9wAzASWRMR4YEkaRtIEYApwFHAGMFfSkKriMzOzHfVW99FE4OGIeBSYBMxP9fOByak8CVgQEVsiYg2wGjihl+IzMzN6LylMAa5N5ZERsQEgvR+U6kcD6wrztKa67UiaLqlFUktbW1uFIZuZDT6VJwVJewDnAT/patIadbFDRcS8iGiOiOampqZdEaKZmSW9caRwJnBvRGxMwxsljQJI75tSfSswtjDfGGB9L8RnZmZJbySFd/O3riOARcDUVJ4K3FSonyJpmKTDgPHA0l6Iz8zMkkpvnS1pb+DtwIcL1XOAhZKmAWuB8wEiYpmkhcByYCswIyK2VRmfmZltr9KkEBHPAy/vUPck2dVItaafDcyuMiYzM6vPv2g2M7Ock4KZmeWcFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMwsV2lSkHSApOslPSRphaQ3SxohabGkVel9eGH6WZJWS1op6fQqYzMzsx1VfaTwDeCXEfFq4GhgBTATWBIR44ElaRhJE4ApwFHAGcBcSUMqjs/MzAoqSwqS9gfeCnwfICJejIingUnA/DTZfGByKk8CFkTElohYA6wGTqgqPjMz21GVRwqHA23ADyT9UdL3JO0DjIyIDQDp/aA0/WhgXWH+1lS3HUnTJbVIamlra6swfDOzwafKpLA7cBzw7Yg4FniO1FVUh2rUxQ4VEfMiojkimpuamnZNpGZmBlSbFFqB1oi4Kw1fT5YkNkoaBZDeNxWmH1uYfwywvsL4zMysg8qSQkQ8DqyTdGSqmggsBxYBU1PdVOCmVF4ETJE0TNJhwHhgaVXxmZnZjnavePkfB34kaQ/gz8AHyBLRQknTgLXA+QARsUzSQrLEsRWYERHbKo7PzMwKKk0KEXEf0Fxj1MQ6088GZlcZk5mZ1edfNJuZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOzXNV3SbUaxs28pdEhmJnV5CMFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlKk0Kkh6R9ICk+yS1pLoRkhZLWpXehxemnyVptaSVkk6vMjYzM9tRbxwpnBIRx0REcxqeCSyJiPHAkjSMpAnAFOAo4AxgrqQhvRCfmZkljeg+mgTMT+X5wORC/YKI2BIRa4DVwAm9H56Z2eBVdVII4NeS7pE0PdWNjIgNAOn9oFQ/GlhXmLc11W1H0nRJLZJa2traKgzdzGzwqfo2FydGxHpJBwGLJT3UybSqURc7VETMA+YBNDc37zDezMx6rtIjhYhYn943ATeQdQdtlDQKIL1vSpO3AmMLs48B1lcZn5mZba+ypCBpH0n7tZeBvwceBBYBU9NkU4GbUnkRMEXSMEmHAeOBpVXFZ2ZmO6qy+2gkcIOk9vX8OCJ+KeluYKGkacBa4HyAiFgmaSGwHNgKzIiIbRXGZ2ZmHVSWFCLiz8DRNeqfBCbWmWc2MLuqmMzMrHP+RbOZmeWcFMzMLFcqKUh6bdWBmJlZ45U9UviOpKWSPirpgCoDMjOzximVFCLiJOA9ZL8jaJH0Y0lvrzQyMzPrdaXPKUTEKuAS4NPA24BvSnpI0jurCs7MzHpX2XMKr5f0NWAFcCpwbkS8JpW/VmF8ZmbWi8r+TuFy4ArgMxHxQntluq/RJZVEZmZmva5sUjgLeKH9F8aSdgP2jIjnI+KayqIzM7NeVfacwq3AXoXhvVOdmZkNIGWTwp4R8Wz7QCrvXU1IZmbWKGWTwnOSjmsfkHQ88EIn05uZWT9U9pzCRcBPJLU/32AU8K5KIjIzs4YplRQi4m5JrwaOJHtC2kMR8ddKIzMzs17XnVtnvwEYl+Y5VhIRcXUlUZmZWUOUSgqSrgGOAO4D2h98E4CTgpnZAFL2SKEZmBARUWUwZmbWWGWTwoPAK4ANFcZiA9i4mbc0ZL2PzDm7Ies166/KJoUDgeWSlgJb2isj4rxKojIzs4YomxQu7ekKJA0BWoDHIuIcSSOA68hOWj8C/GNEPJWmnQVMIztv8YmI+FVP12tmZt1X9nkKvyX7AB+ayncD95Zcx4Vkd1dtNxNYEhHjgSVpGEkTgCnAUcAZwNyUUMzMrJeUvXX2BcD1wHdT1WjgxhLzjQHOBr5XqJ4EzE/l+cDkQv2CiNgSEWuA1cAJZeIzM7Ndo+xtLmYAJwKbIX/gzkEl5vs6cDHwUqFuZERsSMvZUFjOaGBdYbrWVLcdSdMltUhqaWtrKxm+mZmVUTYpbImIF9sHJO1O9juFuiSdA2yKiHtKrkM16nZYR0TMi4jmiGhuamoquWgzMyuj7Inm30r6DLBXejbzR4GfdzHPicB5ks4C9gT2l/RDYKOkURGxQdIoYFOavpXsGdDtxgDrMTOzXlP2SGEm0AY8AHwY+A+y5zXXFRGzImJMRIwjO4H8m4h4L7AImJommwrclMqLgCmShkk6DBgPLO1GW8zMbCeVvSHeS2SP47xiF6xzDrBQ0jRgLXB+WscySQuB5cBWYEb7k97MzKx3lL330Rpq9+8fXmb+iLgduD2VnwQm1pluNjC7zDLNzGzX6869j9rtSfbtfsSuD8fMzBqp7I/Xniy8HouIrwOnVhuamZn1trLdR8cVBncjO3LYr5KIzMysYcp2H321UN5KumfRLo/GzMwaquzVR6dUHYiZmTVe2e6jf+lsfERctmvCMTOzRurO1UdvIPuBGcC5wO/Y/l5FZmbWz3XnITvHRcQzAJIuBX4SER+qKjAzM+t9ZW9zcQjwYmH4RbKH5JiZ2QBS9kjhGmCppBvIftn8DuDqyqIyM7OGKHv10WxJvwD+LlV9ICL+WF1YZmbWCGW7jwD2BjZHxDeA1nQnUzMzG0DKPo7z88CngVmpaijww6qCMjOzxih7pPAO4DzgOYCIWI9vc2FmNuCUTQovRkSQbp8taZ/qQjIzs0YpmxQWSvoucICkC4Bb2TUP3DEzsz6ky6uPJAm4Dng1sBk4EvhcRCyuODYzM+tlXSaFiAhJN0bE8YATgZnZAFa2++gPkt5QaSRmZtZwZZPCKWSJ4WFJ90t6QNL9nc0gaU9JSyX9SdIySV9I9SMkLZa0Kr0PL8wzS9JqSSslnd7zZpmZWU902n0k6ZCIWAuc2YNlbwFOjYhnJQ0F7ki/in4nsCQi5kiaCcwEPi1pAjAFOAo4GLhV0qsiYlsP1m1mZj3Q1ZHCjQAR8ShwWUQ8Wnx1NmNknk2DQ9MrgEnA/FQ/H5icypOABRGxJSLWAKuBE7rZHjMz2wldJQUVyod3d+GShki6D9gELI6Iu4CREbEBIL0flCYfzfbPZ2hNdR2XOV1Si6SWtra27oZkZmad6CopRJ1yKRGxLSKOAcYAJ0h6bSeTq0bdDuuMiHkR0RwRzU1NTd0NyczMOtHVJalHS9pM9oG9VyqThiMi9i+zkoh4WtLtwBnARkmjImKDpFFkRxGQHRmMLcw2Blhfsh1mZrYLdHqkEBFDImL/iNgvInZP5fbhThOCpCZJB6TyXsBpwENkj/ScmiabCtyUyouAKZKGpTuwjgeW9rhlZmbWbWUfstMTo4D5koaQJZ+FEXGzpDvJbpsxDVgLnA8QEcskLQSWA1uBGb7yyMysd1WWFCLifuDYGvVPAhPrzDMbmF1VTGZm1rnuPGTHzMwGOCcFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWa6ypCBprKTbJK2QtEzShal+hKTFklal9+GFeWZJWi1ppaTTq4rNzMxqq/JIYSvwyYh4DfAmYIakCcBMYElEjAeWpGHSuCnAUcAZwFxJQyqMz8zMOqgsKUTEhoi4N5WfAVYAo4FJwPw02XxgcipPAhZExJaIWAOsBk6oKj4zM9tRr5xTkDQOOBa4CxgZERsgSxzAQWmy0cC6wmytqa7jsqZLapHU0tbWVmncZmaDTeVJQdK+wE+BiyJic2eT1qiLHSoi5kVEc0Q0NzU17aowzcyMipOCpKFkCeFHEfGzVL1R0qg0fhSwKdW3AmMLs48B1lcZn5mZba/Kq48EfB9YERGXFUYtAqam8lTgpkL9FEnDJB0GjAeWVhWfmZntaPcKl30i8D7gAUn3pbrPAHOAhZKmAWuB8wEiYpmkhcBysiuXZkTEtgrjMzOzDipLChFxB7XPEwBMrDPPbGB2VTGZmVnn/ItmMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZzknBzMxyTgpmZpar8i6pZg03buYtDVv3I3PObti6zXrKRwpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8tVlhQkXSlpk6QHC3UjJC2WtCq9Dy+MmyVptaSVkk6vKi4zM6uvyiOFq4AzOtTNBJZExHhgSRpG0gRgCnBUmmeupCEVxmZmZjVUlhQi4nfAXzpUTwLmp/J8YHKhfkFEbImINcBq4ISqYjMzs9p6+5zCyIjYAJDeD0r1o4F1helaU90OJE2X1CKppa2trdJgzcwGm75yolk16qLWhBExLyKaI6K5qamp4rDMzAaX3k4KGyWNAkjvm1J9KzC2MN0YYH0vx2ZmNuj1dlJYBExN5anATYX6KZKGSToMGA8s7eXYzMwGvcrukirpWuBk4EBJrcDngTnAQknTgLXA+QARsUzSQmA5sBWYERHbqorNzMxqqywpRMS764yaWGf62cDsquIxM7Ou9ZUTzWZm1gcM6ofsNPIBLGZmfZGPFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHKD+uojsyo16uq2R+ac3ZD12sDgIwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOffKZgNMI28+69/I9H/+UjBzMxyTgpmZpZz95GZ7TK+tUf/1+eOFCSdIWmlpNWSZjY6HjOzwaRPJQVJQ4BvAWcCE4B3S5rQ2KjMzAaPvtZ9dAKwOiL+DCBpATAJWN7QqMzMahiIV3r1taQwGlhXGG4F3licQNJ0YHoafFbSym6u40DgiR5HODB4G3gbwADaBvpKj2ftt9tgJ9oMcGi9EX0tKahGXWw3EDEPmNfjFUgtEdHc0/kHAm8DbwPwNgBvg1r61DkFsiODsYXhMcD6BsViZjbo9LWkcDcwXtJhkvYApgCLGhyTmdmg0ae6jyJiq6SPAb8ChgBXRsSyXbyaHnc9DSDeBt4G4G0A3gY7UER0PZWZmQ0Kfa37yMzMGshJwczMcoMqKQymW2hIekTSA5Luk9SS6kZIWixpVXofXph+VtouKyWd3rjIe07SlZI2SXqwUNftNks6Pm271ZK+KanWpdJ9Tp32XyrpsbQf3CfprMK4AdV+AEljJd0maYWkZZIuTPWDZj/YaRExKF5kJ64fBg4H9gD+BExodFwVtvcR4MAOdf8GzEzlmcBXUnlC2h7DgMPSdhrS6Db0oM1vBY4DHtyZNgNLgTeT/W7mF8CZjW7bTrT/UuBTNaYdcO1PsY8Cjkvl/YD/Tm0dNPvBzr4G05FCfguNiHgRaL+FxmAyCZifyvOByYX6BRGxJSLWAKvJtle/EhG/A/7SobpbbZY0Ctg/Iu6M7JPh6sI8fVqd9tcz4NoPEBEbIuLeVH4GWEF2p4RBsx/srMGUFGrdQmN0g2LpDQH8WtI96dYgACMjYgNk/zzAQal+IG+b7rZ5dCp3rO/PPibp/tS91N5tMuDbL2kccCxwF94PShtMSaHLW2gMMCdGxHFkd5ydIemtnUw72LYN1G/zQNsW3waOAI4BNgBfTfUDuv2S9gV+ClwUEZs7m7RG3YDZDj0xmJLCoLqFRkSsT++bgBvIuoM2psNi0vumNPlA3jbdbXNrKnes75ciYmNEbIuIl4Ar+Fu34IBtv6ShZAnhRxHxs1Q9qPeD7hhMSWHQ3EJD0j6S9msvA38PPEjW3qlpsqnATam8CJgiaZikw4DxZCfZBoJutTl1LTwj6U3papP3F+bpd9o/CJN3kO0HMEDbn2L+PrAiIi4rjBrU+0G3NPpMd2++gLPIrkZ4GPhso+OpsJ2Hk11R8SdgWXtbgZcDS4BV6X1EYZ7Ppu2ykn56lQVwLVkXyV/JvulN60mbgWayD8+HgctJv/zv66867b8GeAC4n+wDcNRAbX+K/SSybp77gfvS66zBtB/s7Mu3uTAzs9xg6j4yM7MuOCmYmVnOScHMzHJOCmZmlnNSMDOznJOCWQ2Snq14+RdJ2ru31mdWlpOCWWNcBOzd1URmva1PPaPZrC+TdATwLaAJeB64ICIeknQVsJnsx06vAC6OiOsl7Ub2o6e3AWvIvoRdCRycXrdJeiIiTknLnw2cA7wATIqIjb3ZPjPwkYJZd8wDPh4RxwOfAuYWxo0i+zXtOcCcVPdOYBzwOuBDZPfmJyK+SXYfnVPaEwKwD/CHiDga+B1wQaUtMavDRwpmJaS7br4F+EnhAVzDCpPcGNlN55ZLGpnqTgJ+kuofl3RbJ6t4Ebg5le8B3r7LgjfrBicFs3J2A56OiGPqjN9SKKvDexl/jb/dc2Yb/t+0BnH3kVkJkd2Tf42k8yG7G6eko7uY7Q7gf0naLR09nFwY9wzZ4yLN+hQnBbPa9pbUWnj9C/AeYJqk9rvPdvU415+S3a30QeC7ZE8A+580bh7wiy66lMx6ne+SalYhSftGxLOSXk72jIoTI+LxRsdlVo/7Lc2qdbOkA4A9gC86IVhf5yMFMzPL+ZyCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZ7v8D6biaAP4H4jYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.hist(length)\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency of Lengths in Documents')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e2d34c",
   "metadata": {},
   "source": [
    "### 1.d)  Tokenize each text document using rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ae42a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = alldata[0:1400]\n",
    "test = alldata[1400:]\n",
    "t = Tokenizer(5000)\n",
    "t.fit_on_texts(train)\n",
    "sequences = t.texts_to_sequences(train)\n",
    "sequences_test = t.texts_to_sequences(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d059078",
   "metadata": {},
   "source": [
    "### 1.e) Select a review length L that 70% of the reviews have a length below it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd579203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737\n"
     ]
    }
   ],
   "source": [
    "lengthsorted = sorted(length)\n",
    "print(lengthsorted[1399])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34676f94",
   "metadata": {},
   "source": [
    "L = 737"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69af065",
   "metadata": {},
   "source": [
    "### 1.f) Shape reviews so that they are all length L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a84c5074",
   "metadata": {},
   "outputs": [],
   "source": [
    "shaped_train_5000 = pad_sequences(sequences, maxlen = 737)\n",
    "shaped_test_5000 = pad_sequences(sequences_test, maxlen = 737)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d61ed",
   "metadata": {},
   "source": [
    "### 1.g) Created an embedding layer using the top 5000 words. Length of the embedding vector for each word is 32. Flatten the matrix of each document to a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e809f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 737\n",
    "top_words = 5001\n",
    "max_words = L\n",
    "embedding = Embedding(top_words, 32, input_length=max_words)\n",
    "flatten = Flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fa3a6b",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron\n",
    "### 2. Train a MLP with three hidden layers each of which has 50 ReLUs and one output layer with a single sigmoid neuron. Set epochs to 2 to avoid overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d49bffa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "140/140 [==============================] - 3s 15ms/step - loss: 0.6959 - accuracy: 0.5129\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 0.6642 - accuracy: 0.5843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14d5f36d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(embedding)\n",
    "model.add(flatten)\n",
    "\n",
    "firstDense = tf.keras.layers.Dense(units=50, activation='relu')\n",
    "model.add(firstDense)\n",
    "\n",
    "firstDropout = tf.keras.layers.Dropout(.2)\n",
    "model.add(firstDropout)\n",
    "\n",
    "secondDense = tf.keras.layers.Dense(units=50, activation='relu')\n",
    "model.add(secondDense)\n",
    "\n",
    "nextDropout = tf.keras.layers.Dropout(.5)\n",
    "model.add(nextDropout)\n",
    "\n",
    "thirdDense = tf.keras.layers.Dense(units=50, activation='relu')\n",
    "model.add(thirdDense)\n",
    "\n",
    "model.add(nextDropout)\n",
    "\n",
    "lastDense = tf.keras.layers.Dense(units=1, activation = 'sigmoid')\n",
    "model.add(lastDense)\n",
    "\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics='accuracy')\n",
    "model.fit(shaped_train_5000, sig_lab[0:1400], epochs=2, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f1d27d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 5ms/step - loss: 0.5142 - accuracy: 0.7586\n",
      "Train accuracy: 0.758571445941925\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(shaped_train_5000, sig_lab[0:1400])\n",
    "print(\"Train accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e87faa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6756 - accuracy: 0.5717\n",
      "Test accuracy 0.5716666579246521\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(shaped_test_5000, sig_lab[1400:] )\n",
    "print(\"Test accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27dcb2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 737, 32)           160032    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 23584)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                1179250   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,344,433\n",
      "Trainable params: 1,344,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559a9103",
   "metadata": {},
   "source": [
    "## One Dimensional Convolutional Neural Network. \n",
    "\n",
    "### 3. Inserted a Conv1D layer after the embedding layer. This convolutional layer has 32 feature maps with kernel size of 3. The convolutional layer is followed by a 1D max pooling layer with a length and stride of 2. The rest of the network is the same as the neural network above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01be1fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "140/140 [==============================] - 4s 20ms/step - loss: 0.7004 - accuracy: 0.4907\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 2s 17ms/step - loss: 0.6871 - accuracy: 0.5521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14d56d850>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "L = 737\n",
    "top_words = 5001\n",
    "max_words = L\n",
    "#shaped_train_5000 = np.where(shaped_train > 5000, 0, shaped_train)\n",
    "embedding = Embedding(top_words, 32, input_length=max_words)\n",
    "conv1d = tf.keras.layers.Conv1D(32, 3)\n",
    "maxpool = tf.keras.layers.MaxPooling1D(2)\n",
    "flatten = Flatten()\n",
    "model.add(embedding)\n",
    "model.add(conv1d)\n",
    "model.add(maxpool)\n",
    "model.add(flatten)\n",
    "\n",
    "\n",
    "firstDense = tf.keras.layers.Dense(units=50, activation='relu')\n",
    "model.add(firstDense)\n",
    "firstDropout = tf.keras.layers.Dropout(.2)\n",
    "model.add(firstDropout)\n",
    "secondDense = tf.keras.layers.Dense(units=50, activation='relu')\n",
    "model.add(secondDense)\n",
    "nextDropout = tf.keras.layers.Dropout(.5)\n",
    "model.add(nextDropout)\n",
    "thirdDense = tf.keras.layers.Dense(units=50, activation='relu')\n",
    "model.add(thirdDense)\n",
    "model.add(nextDropout)\n",
    "lastDense = tf.keras.layers.Dense(units=1, activation = 'sigmoid')\n",
    "model.add(lastDense)\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics = 'accuracy')\n",
    "sig_lab = np.array(sig_lab)\n",
    "model.fit(shaped_train_5000, sig_lab[0:1400], epochs=2, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e62aa17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 7ms/step - loss: 0.6208 - accuracy: 0.8693\n",
      "Train accuracy: 0.8692857027053833\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(shaped_train_5000, sig_lab[0:1400])\n",
    "print(\"Train accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87f6f35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6727 - accuracy: 0.6867\n",
      "Test accuracy 0.6866666674613953\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(shaped_test_5000, sig_lab[1400:] )\n",
    "print(\"Test accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbdeb4c",
   "metadata": {},
   "source": [
    "## Long Short-Term Memory Recurrent Neural Network\n",
    "\n",
    "### 4. Each word is represented to LSTM as a vector of 32 elements and the LSTM is followed by a dense layer of 256 ReLUs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fba7b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "140/140 [==============================] - 30s 198ms/step - loss: 0.6944 - accuracy: 0.5200\n",
      "Epoch 2/20\n",
      "140/140 [==============================] - 27s 192ms/step - loss: 0.5311 - accuracy: 0.7429\n",
      "Epoch 3/20\n",
      "  4/140 [..............................] - ETA: 32s - loss: 0.1494 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "embedding = Embedding(top_words, 32, input_length=max_words)\n",
    "model.add(embedding)\n",
    "lstm = tf.keras.layers.LSTM(32)\n",
    "model.add(lstm)\n",
    "firstDropout = tf.keras.layers.Dropout(.2)\n",
    "model.add(firstDropout)\n",
    "firstDense = tf.keras.layers.Dense(units=256, activation='relu')\n",
    "model.add(firstDense)\n",
    "model.add(firstDropout)\n",
    "lastDense = tf.keras.layers.Dense(units=1, activation = 'sigmoid')\n",
    "model.add(lastDense)\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(shaped_train_5000, sig_lab[0:1400], epochs=20, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce82573c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 4s 73ms/step - loss: 9.4192e-06 - accuracy: 1.0000\n",
      "Train accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(shaped_train_5000, sig_lab[0:1400])\n",
    "print(\"Train accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c941ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 76ms/step - loss: 1.5393 - accuracy: 0.7867\n",
      "Test accuracy 0.7866666913032532\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(shaped_test_5000, sig_lab[1400:] )\n",
    "print(\"Test accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a9962e",
   "metadata": {},
   "source": [
    "References:  \n",
    "https://www.geeksforgeeks.org/python-remove-punctuation-from-string/\n",
    "https://www.geeksforgeeks.org/how-to-iterate-over-files-in-directory-using-python/\n",
    "https://www.w3schools.com/python/python_file_open.asp  \n",
    "https://stackoverflow.com/questions/51956000/what-does-keras-tokenizer-method-exactly-do  \n",
    "https://medium.com/geekculture/nlp-with-tensorflow-keras-explanation-and-tutorial-cae3554b1290  \n",
    "https://medium.com/analytics-vidhya/understanding-embedding-layer-in-keras-bbe3ff1327ce  \n",
    "https://stackoverflow.com/questions/40050397/deep-learning-nan-loss-reasons  \n",
    "https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/  \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
